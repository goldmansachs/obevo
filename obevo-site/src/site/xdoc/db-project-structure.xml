<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 Goldman Sachs.
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.

-->
<document xmlns="http://maven.apache.org/XDOC/2.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/XDOC/2.0 http://maven.apache.org/xsd/xdoc-2.0.xsd">
    <properties>
        <title>DB Project Structure</title>
    </properties>
    <body>
        <section name="DB Project Structure">
            <p>Obevo allows users to maintain their database scripts in an object-based structure, such as the structure
            below. This page describes how to implement this.</p>
            <img src="images/db-kata-file-setup.jpg" alt="" />
            <br/>
            <macro name="toc">
                <param name="fromDepth" value="0" />
                <param name="toDepth" value="1" />
            </macro>
        </section>
        <section name="system-config.xml">
            <subsection name="Base Structure">

                <p>The system-config.xml file is the starting point of your db source code. Hence, the directory containing it is your db root folder</p>
                <ul>
                    <li>It is located under src/main/database to abide by Maven conventions; however, this is not mandatory</li>
                </ul>
                <p>system-config.xml defines:</p>
                <ul>
                    <li>The <u><i>logical schemas</i></u> that this unit of code would maintain (in this example, we only maintain 1 logical schema DEMOSCHEMA)
                        <ul>
                            <li>By logical schema - we refer to the schema that we would ideally see in a particular production environment</li>
                            <li>Compare this to the <u><i>physical schema</i></u>, which may have a suffix appended depending on the environment
                                <ul>
                                    <li>e.g. in prod, we have DEMOSCHEMA</li>
                                    <li>in uat, we have DEMO<i>SCHEMA</i>UAT1</li>
                                    <li>in dev, we have DEMO<i>SCHEMA</i>DEV1</li>
                                    <li>and so on</li>
                                </ul>
                            </li>
                            <li>
                                <font color="red">NOTE for Sybase ASE users: The "schema" term in Obevo is
                                    equivalent to the Sybase ASE "database". The ASE schema concept is not used; the default is
                                    assumed.
                                </font>
                            </li>
                        </ul>
                    </li>
                    <li>The
                        <u><i>db environments</i></u> that we plan on deploying to
                        <ul>
                            <li>e.g. dev1 environments deploys to myserver1.dev.me.com:1234, prod deploys to myserver1.prod.me.com:1234</li>
                        </ul>
                    </li>
                </ul>
                <p>You can read the provided
                    <a href="https://github.com/goldmansachs/obevo-kata/tree/master/src/main/database/system-config.xml">system-config.xml file</a>
                    for some of the features and configurations that you can define
                </p>

                <p>A couple of the key configs to note (see the xml example for details):</p>
            </subsection>
            <subsection name="Defining your DB Connection">

                <p>You can define your DB connection in 3 different ways:</p>
                <ul>
                    <li>via the jdbcUrl attribute, where you simply provide the JDBC url; e.g. db2://myhost1.me.com:1234/MYSERVER</li>
                    <li>via the dbHost, dbSchema, and dbServer attributes, where you provide those and the underlying
                        JDBC url is constructed for you; e.g. dbHost=&quot;myhost1.me.com&quot; dbPort=&quot;1234&quot; dbServer=&quot;MYSERVER1&quot;</li>
                    <li>via the dbDataSourceName, where you provide the LDAP name and the tool will look up the source in LDAP; e.g. dbDataSourceName=MYSERVER1</li>
                </ul>
            </subsection>
            <subsection name="Schema Suffix or Prefix Convention">

                <p>The dbSchemaPrefix and/or dbSchemaSuffix attributes can be used to add a prefix or suffix across
                    your logical schemas when pointing to a particular environment
                </p>
                <ul>
                    <li>This is to help enforce the convention of having a consistent schema naming convention across
                        environments
                        <ul>
                            <li>e.g. &lt;SCHEMA<i>NAME&gt;&lt;ENVIRONMENT</i>SUFFIX&gt;
                            </li>
                            <li>From anecdotal evidence, most teams go w/ the suffix convention, but a few go w/
                                prefixes, e.g.
                                &lt;ENVIRONMENT<i>PREFIX&gt;&lt;SCHEMA</i>NAME&gt;
                            </li>
                        </ul>
                    </li>
                    <li>In case your system already has the schemas defined and need to define the schema names outside
                        of this
                        convention, you can use the &lt;schemaOverrides&gt; element.
                        <ul>
                            <li>Note that the overrideValue will override even the environment suffix/prefix convention
                                if you
                                have specified it
                            </li>
                            <li>See the example below</li>
                        </ul>
                    </li>
                </ul>
                <source><![CDATA[<!--schema override example -->
<dbSystemConfig type="DB2">
	<schemas>
		<schema name="SCHEMA1" />
		<schema name="SCHEMA2" />
		<schema name="SCHEMA3" />
	</schemas>
	<environments>
		<dbEnvironment name="test" type="DEV" dbServer="example" ...>
			<schemaOverrides>
				<schemaOverride schema="SCHEMA1" overrideValue="my_schema1abc" />
				<schemaOverride schema="SCHEMA2" overrideValue="my_schema2def" />
				<!-- you don't have to specify an override if you don't want to, say for SCHEMA3 in this example. Then, it will just take the original value -->
			</schemaOverrides>
			...
		</dbEnvironment>
	</environments>
</dbSystemConfig>]]></source>
            </subsection>
            <subsection name="Advanced Environment Management">
                <p>You can do more advanced environment management with Obevo, including tokenization, permission
                    management, and environment-specific deployments.
                </p>

                <p>See the
                    <a href="environment-management.html">Environment Management page</a>
                    for more information,
                    though you should first understand the rest of this page and the DB project structure basics.
                </p>
            </subsection>
        </section>
        <section name="Schema folders">
            <p>Underneath your root folder, you should define a folder for each of the logical schemas that you will
                maintain in this module.
            </p>

            <p>For each schema, you will then define the table, sp, view, data, ... folders</p>
        </section>
        <section name="File Structure (for all object types)">
            <subsection name="Structure">

                <p>Your table definitions will go under the table folder in the schemas</p>

                <p>As mentioned in the intro doc, the goal here is to promote a db-object-oriented structure for your
                    code base.
                    Hence:
                </p>
                <ul>
                    <li>Particular object types are rooted under folders of that name (e.g. tables go in /table, stored
                        procedures under /sp, /view, /function, /data, /sequence, and so on)
                    </li>
                    <li>Changes for a particular db object will go into a file named of that object, e.g.
                        <source><![CDATA[table/PRODUCT.sql
table/ACCOUNT.ddl
table/ENTITY.sql
table/codes/NET_TYPE.sql
table/codes/INSTRUMENT.ddl
table/codes/PROD_TYPE.fx.abc.sql
table/codes/PROD_TYPE.fi.abc.sql
view/V_PRODUCT.sql
view/V_ENTITY.sql
sp/CREATE_PRODUCT.ddl
data/codes/INSTRUMENT.sql
data/NET_TYPE.csv]]></source>
                    </li>
                </ul>
            </subsection>
            <subsection name="Naming rules / flexibilities">

                <p>The only rules to consider here are:</p>
                <ol style="list-style-type: decimal">
                    <li>The DB object name should be the first segment of the file name (i.e. before the first dot)
                        <ol style="list-style-type: decimal">
                            <li>e.g. PRODUCT.sql would correspond to a table named PRODUCT</li>
                            <li>e.g. ACCOUNT.sql would correspond to a table named ACCOUNT</li>
                            <li>e.g. PROD<i>TYPE.fx.abc.sql would correspond to a table named PROD</i>TYPE (i.e. the
                                intermediate .fx.abc. does not matter
                            </li>
                        </ol>
                    </li>
                    <li>The DB object names must be unique for a particular environment (e.g. multiple files for DB
                        objects
                        named PRODUCT cannot be defined for a particular environment)
                        <ol style="list-style-type: decimal">
                            <li>In a later section, we will show how to have environment-specific inclusions/exclusions
                                of
                                objects, which would allow the structure involving PROD
                                <i>TYPE.fi.abc.sql and PROD</i>
                                TYPE.fx.abc.sql above (not that we encourage doing this a lot)
                            </li>
                        </ol>
                    </li>
                </ol>
                <p>In terms of what you are flexible with:</p>
                <ul>
                    <li>You can define your table files anywhere under /table, i.e. you can put them in subdirectories
                    </li>
                    <li>The extension does not matter - can be ddl, sql, txt, whatever</li>
                </ul>
                <p>This applies for all object types</p>
            </subsection>
            <subsection name="Common content conventions">

                <p>You can use the ${token} convention to replace tokens that you've defined in system-config.xml</p>

                <p>Now we discuss the specific content rules for each of the object types</p>

                <p>Stored procedures, views, and data are very easy to define in Obevo; but given that tables
                    are focal
                    point of databases, we will start there
                </p>
            </subsection>
        </section>
        <section name="Defining Table Changes">
            <p>Below is an example of a table file. We will describe below:</p>
            <source><![CDATA[//// CHANGE name=chng1
CREATE TABLE TABLE_A (
	A_ID    INT	NOT NULL,
	B_ID    INT	NOT NULL,
	STRING_FIELD	VARCHAR(30)	NULL,
	TIMESTAMP_FIELD	TIMESTAMP	NULL,
	PRIMARY KEY (A_ID)
)
GO
//// CHANGE name=chng3
ALTER TABLE TABLE_A ADD COLUMN C_ID INT NULL
GO
//// CHANGE name=chng2
ALTER TABLE TABLE_A ADD FOREIGN KEY FK_B (B_ID) REFERENCES TABLE_B(B_ID)
GO
//// CHANGE name=mytrigger
CREATE TRIGGER mytrigger ON TABLE_A
FOR abc123 ...
GO
//// CHANGE name=extra1
ALTER TABLE TABLE_A ADD COLUMN EXTRA1 INT NULL
GO]]></source>
            <p>Basically, all alters on a table (including CREATE TABLE, ALTER TABLE, adding constraints, adding
                indexes, adding FKs or triggers) will go into this file
            </p>

            <p>Each change for a particular release or functionality should be demarcated using the &quot;//// CHANGE
                name=123&quot; annotation
            </p>
            <ul>
                <li>The name must be distinct
                    <i>within</i>
                    the file. The same name could exist in different files
                </li>
                <li>A convention that teams have used for the name is to use the JIRA ticket number of the issue orcommit</li>
            </ul>

            <p>If you use the global permissions functionality, you do not need to define GRANT statements in your
                files! The tool will automatically execute these for you upon detecting a &quot;CREATE TABLE&quot; phrase
                (whitespace between CREATE and TABLE is taken care of)
            </p>

            <subsection name="Immutable //// CHANGE sections">
                <p>Once a change is deployed to an environment,
                    <u>
                        <b>
                            <i>it cannot be modified or deleted</i>
                        </b>
                    </u>
                    (*)
                </p>
                <ul>
                    <li>You must create a new alter statement. This is required to guarantee that we can always replay all
                        the changes in a DB file to recreate the schema from scratch
                    </li>
                    <li>Modifying white-space is fine; the tool will tolerate that. But changing actual content will fail.</li>
                    <li>Fyi, the tool does this by taking a MD5 hash of the change content and storing it in the audit table</li>
                </ul>
                <p>(*) - For special cases (e.g. undoing a change deployed to UAT but not prod), a //// CHANGE can be removed
                    with a special directive in the code. See the
                    <a href="rollback.html">Rollback</a>
                    page for details.
                </p>
            </subsection>

            <subsection name="Dropping tables and removing table files">
                <p>Given that changes are immutable, can I drop a table and then remove a file? Yes, but with special
                    directives. We do not want to just delete a file and have the table dropped, as we can't foresee any
                    cases of accidentally dropping or renaming a file; we want to be conservative in this case
                </p>
                <p>Steps for dropping a table:
                    <ol>
                        <li>Add a new change w/ the DROP_TABLE toggle, per the following example. Note that no SQL needs
                            to be provided; in the future, we will allow users to enter their own SQL in that section to execute.
                        </li>
                        <source><![CDATA[//// CHANGE name=chng1
CREATE TABLE TABLE_DROP (
	ID INT NOT NULL,
    PRIMARY KEY (ID)
)
GO

//// CHANGE name=drop DROP_TABLE
]]></source>
                        <li>Deploy this change across all environments to drop the table. This will also clear the DeployLog
                            table of this object.
                        </li>
                        <li>You are then free to delete the file from your source code. Note that if you were to deploy
                            your source code to a brand new DB, then this file will not get deployed (the existence of
                            the DROP_TABLE command will preclude it).
                        </li>
                    </ol>
                </p>
            </subsection>

            <subsection name="Renaming tables">
                <p>You have a couple options on renaming tables in Obevo</p>
                <h4>Option 1: Create the new table and migrate the data over</h4>
                <p>The migration SQL should be in a /migration change (described in the sections below), so that the
                    object files remain clean
                </p>
                <p>The changes will also need the dependencies attributes to ensure ordering of the files (see the
                    subsequent sections for more information on migrations and dependencies)
                </p>

                <p>### /table/OrigTable.sql</p>
                <source><![CDATA[//// CHANGE name="init"
CREATE TABLE OrigTable (
    Field1 int,
    Field2 int
)
GO
//// CHANGE name="dropOld" DROP_TABLE dependencies="OldToNewTableMigration.migration"]]></source>

                <p>### /table/NewTable.sql</p>
                <source><![CDATA[//// CHANGE name="init"
CREATE TABLE NewTable (
    NewField1 int,
    NewField2 int
)]]></source>

                <p>### /migration/OldToNewTableMigration.sql</p>
                <source><![CDATA[
//// CHANGE name="migration" includeDependencies="OrigTable.init,NewTable.init"
INSERT INTO NewTable (NewField1, NewField2)
SELECT Field1, Field2 FROM OrigTable
GO]]></source>
                <h4>Option 2: Use the rename command provided by the DBMS</h4>

                <p>As of this version, doing this in Obevo is a bit clunky, as you won't be able to delete
                    the old file, and the new file would not have the DDL defined. Suggestions to work around this for now:
                    <ul>
                        <li>If you need this for in-memory testing, use the workarounds for manually defining a
                            translation SQL defined
                            <a href="in-memory-db-testing">here</a>
                        </li>
                        <li>If you want to redefine the new file to define the change SQL in a cleaner way, see the
                            <a href="incremental-change-code-cleanup.html">re-baselining documentation</a>.
                        </li>
                    </ul>
                </p>
                <p>### /table/OrigTable.sql</p>
                <source><![CDATA[//// CHANGE name="init"
CREATE TABLE OrigTable (
    Field1 int,
    Field2 int
)
GO
//// CHANGE name="dropOld" DROP_TABLE dependencies="OldToNewTableMigration.migration"]]></source>

                <p>### /table/NewTable.sql</p>
                <source><![CDATA[//// CHANGE name="init" dependencies="OrigTable.init"
sp_rename 'OrigTable', 'NewTable']]></source>
            </subsection>
        </section>
        <section name="Defining Rerunnable Object Changes (Stored Procedures, Views, Functions, ...)">
            <p>This spans the following object types (and this would be the directory structure you'd apply for each)
            </p>
            <table>
                <tr><th>Object Type</th><th>Directory</th><th>Vendor-specific Notes</th></tr>
                <tr><td>Stored Procedures</td><td>/sp</td><td></td></tr>
                <tr><td>Views</td><td>/view</td><td></td></tr>
                <tr><td>Functions</td><td>/function</td><td></td></tr>
                <tr><td>Sequences</td><td>/sequence</td><td></td></tr>
                <tr><td>Triggers</td><td>/trigger</td><td></td></tr>
                <tr><td>User Types</td><td>/usertype</td><td>Only Sybase ASE and MS SQL Server</td></tr>
                <tr><td>Rule</td><td>/rule</td><td>Only Sybase ASE and MS SQL Server</td></tr>
                <tr><td>Default</td><td>/default</td><td>Only Sybase ASE and MS SQL Server</td></tr>
                <tr><td>Packages + Package Bodies</td><td>/routinepackage</td><td>Only for Oracle</td></tr>
                <tr><td>Synonyms</td><td>/synonym</td><td>Currently only for Oracle; other vendors will be supported later</td></tr>
            </table>
            <p>Here is an example:</p>
            <source><![CDATA[CREATE PROCEDURE SP1 ()
LANGUAGE SQL DYNAMIC RESULT SETS 1
BEGIN ATOMIC
    CALL SP2(2);
    CALL SP2(3);
END
GO]]></source>
            <p>That's it! Just a matter of creating, editing, and deleting the file; just like Java. i.e.</p>
            <ul>
                <li>To create the SP/view/..., create the file w/ the create statement content (along w/ adding the
                    grants
                    if you've defined the global permissions)
                </li>
                <li>To edit the SP/view/..., edit the file. Obevo will do the drop/add for you (along w/
                    re-adding
                    the grants if you've defined the global permissions)
                </li>
                <li>To drop the SP/view/..., delete the file. Obevo will do the drop for you</li>
            </ul>
            <p>Do not define the &quot;DROP PROCEDURE/VIEW/...&quot; statement in your file. The tool does it for you
            </p>
            <subsection name="Side use-case for SPs with function overloads">

                <p>For cases where you have SPs of the same name, but different argument lengths, those should be
                    defined in the
                    same file
                </p>

                <p>Obevo will take care of dropping each of the instances as needed</p>
            </subsection>
            <subsection name="Objects with BODY components, e.g. Oracle packages">
                <p>Some database objects, such as <a href="https://docs.oracle.com/cd/B19306_01/appdev.102/b14261/packages.htm">Oracle packages</a>,
                are defined across two SQL statements: a declaration of the object signature, and its implementation.</p>
                <p>The implementation can be more complex, esp. with referring to other objects, and so we would not want
                to force the two to be deployed in sequence.</p>
                <p>Hence, we allow the file content to be split in two using the "//// BODY" line; the content preceding
                that line is the signature, and afterward the implementation body. See below for an example:</p>
                <source><![CDATA[CREATE OR REPLACE PACKAGE MY_EXAMPLE_PACKAGE
AS
    FUNCTION MY_FUNC1 return integer;
    FUNCTION MY_FUNC2(var1 IN integer) return integer;
END;
GO

//// BODY
CREATE OR REPLACE PACKAGE BODY MY_EXAMPLE_PACKAGE
AS
    FUNCTION MY_FUNC1
    RETURN integer IS
    BEGIN
        RETURN 1;
    END;

    FUNCTION MY_FUNC2 (var1 IN integer)
    RETURN integer IS
    BEGIN
        RETURN 1;
    END;
END;
GO
]]></source>
            </subsection>
        </section>
        <section name="DB Object Deployment Order">
            <p>A key tenet of Obevo is to not require excessive overhead on developers to define the order of
                db changes for
                <i>
                    <u>every single change</u>
                </i>
                , e.g. via a sequence file or a versioning convention.
                It tries to be similar to application languages, e.g. Java, where users do not worry about the
                compilation order of classes within a module.
            </p>

            <p>Obevo takes care of this by:
                <ol>
                    <li>Inferring dependency order across objects by inspecting the text</li>
                    <li>Allowing users to explicitly define a dependency order if needed to override the default behavior</li>
                </ol>

                See the
                <a href="design-walkthrough.html#Sorting_Changes_in_the_file-per-object_format">Design Walkthrough</a>
                for more details on how this is done.
            </p>

            <p>Specific steps on applying this to your code:</p>
            <subsection name="Automatic Inference of Order Based on the Code">
                Order across all object types is inferred automatically based on the code of the object or CHANGE, except:
                <ul>
                    <li>staticdata: The dependencies are inferred based on the foreign key relations defined in the associated table change</li>
                    <li>migration: No automatic inference is done. Users will have to define dependencies explicitly</li>
                </ul>

            </subsection>
            <subsection name="Explicit dependency definition by users to override/supplement the inferred dependency">
                <p>To define the dependency explicitly, add the "dependencies", "includeDependencies", or "excludeDependencies"
                    value to either the //// CHANGE line (for incremental changes) or //// METADATA line (for rerunnable objects)
                </p>

                <p>The value is a comma-separated string that points to the dependencies of that change:
                    <ul>
                        <li>dependencies: overrides the value inferred by Obevo entirely w/ what the user provides</li>
                        <li>includeDependencies: adds the given dependencies to the value inferred by Obevo</li>
                        <li>excludeDependencies: removes the given dependencies from the value inferred by Obevo</li>
                    </ul>
                </p>

                <p>When to use each:
                    <ul>
                        <li>excludeDependencies is the most common use case, as you will usually have to exclude the false positives from the dependency detection
                            (e.g. from comments and strings)
                        </li>
                        <li>includeDependencies is for rarer cases, say if you need to include a cross-schema object dependency</li>
                        <li>dependencies is useful for "migration" change types (see below) that really require explicit dependency ordering</li>
                    </ul>
                </p>

                <p>
                    String format for each dependency is one of the following:
                    <ul>
                        <li>[objectName]</li>
                        <li>[objectName].[changeName]</li>
                        <li>[logicalSchemaName].[objectName]</li>
                        <li>[logicalSchemaName].[objectName].[changeName]</li>
                    </ul>
                </p>

                <p>
                    Examples:
                    <li>//// METADATA dependencies=&quot;sp1,sp2&quot; =&gt;would force the dependencies of the object to be sp1,sp2</li>
                    <li>//// METADATA excludeDependencies=&quot;schema1.sp3&quot; =&gt; would exclude schema1.sp3 from the automatic dependency calculation</li>
                    <li>//// CHANGE name="chng1" includeDependencies=&quot;myobject.chngABC&quot; =&gt; would include
                        myobject.chngABC in the dependency calculation
                    </li>
                </p>
            </subsection>
            <subsection name="Tie-break logic for consistent order">
                <p>After the dependencies are declared, the changes are deployed respecting that order using<a
                    href="https://en.wikipedia.org/wiki/Topological_sorting">Topological Sort</a>.
                    Apart from those mandated dependency orders, the sort order will break ties based on the following
                    change types:
                </p>
                <ol style="list-style-type: decimal">
                    <li>Sequences</li>
                    <li>Table changes</li>
                    <li>Functions</li>
                    <li>Views</li>
                    <li>Stored Procedures</li>
                    <li>Migrations</li>
                    <li>Static Data</li>
                </ol>
            </subsection>
        </section>
        <section name="Managing Static Data / Code Tables">
            <p>Many systems store tables just for static/code data, not necessarily dynamic data.</p>

            <p>For these cases, Obevo supports maintaining these as rerunnable files, such that if you wanted
                to
                add/modify/delete a row, you can just edit the file content in place, instead of having to specifically
                code
                to an incremental update statement.
            </p>

            <p>These would go under the /staticdata folder in your schema (i.e. at the same level as /table, /sp, /view,
                etc.
            </p>

            <p>Within that folder, you can use 2 methodologies for organizing your data, depending on which use case
                fits
                you better. (both can coexist within that folder and be used for different tables in the folder)
            </p>
            <subsection name="Methodology 1) File-per-table (the common use case)">

                <p>Here, we define a file per code table (i.e. the same paradigm that we use for the other objects in
                    obevo, like tables/sps/views/etc.)
                </p>

                <p>e.g. say we want to maintain static data for 3 tables, VIEW<i>DEF, VIEW</i>COLUMN, COLUMNDEF; the
                    directory
                    would look like this:
                </p>
                <source><![CDATA[/myschema/staticdata
/myschema/staticdata/VIEW_DEF.csv
/myschema/staticdata/VIEW_COLUMN.sql
/myschema/staticdata/COLUMN_DEF.csv]]></source>
                <p>In terms of the actual content format of that file (i.e. how to represent the static data), you have
                    two
                    options:
                </p>
                <h3>Content Option A) via simple delete/insert statements</h3>

                <p>See the example below; hence, every time you change this file, the script will be rerun (delete all,
                    insert
                    all)
                </p>

                <p>This is a simple option and what you'd be used to if doing manual deployments; but if you want a
                    nicer form
                    of representation (or just don't want to delete all your rows for a deployment), then try the CSV
                    option...
                </p>
                <source><![CDATA[DELETE FROM COLUMN_DEF
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (20, 'col1', '2012-01-01 12:12:12')
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (21, 'col2', '2013-01-01 11:11:11.65432')
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (22, 'col3', null)
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (50, 'txncol1', null)
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (51, 'txncol2', '2012-01-01 12:12:12')
GO
INSERT INTO COLUMN_DEF (COLUMN_ID, COLUMN_NAME, ADD_TIME) VALUES (52, 'txncol3', '2013-01-01 11:11:11.65432')
GO]]></source>
                <h3>Content Option B) via CSV (the preferred method)</h3>
                <source><![CDATA[COLUMN_ID, COLUMN_NAME, ADD_TIME
20, "col1", "2012-01-01 12:12:12"
21, "col2", "2013-01-01 11:11:11.65432"
22, "col3", null
50, "txncol1", null
51, "txncol2", "2012-01-01 12:12:12"
52, "txncol3", "2013-01-01 11:11:11.65432"]]></source>
                <p>Just define a CSV file (quotes are supported, as is changing the comma delimiter and null token) with
                    the first row as the column names, and you are set
                </p>

                <p>If a change is done on the table, Obevo will only deploy the incremental change (it will
                    compare the full dataset in the db table vs. the file and apply the appropriate insert/update/delete)
                </p>

                <p>Note that there is reverse-engineering available to make this easy to onboard for existing projects (see below)</p>

                <p>A specific requirement - the table must have a primary key or unique index defined, whether physically
                    on the table, or configured in code. Specifically:
                </p>
                <ul>
                    <li>Define a primary key or unique index if one doesn't exist already (it would be bad practice not to have it)</li>
                    <li>Or define a metadata attribute as follows:
                        <source><![CDATA[//// METADATA primaryKeys="field1,field2"
field1,field2,value
a,b,11
c,d,22]]></source>
                    </li>
                    <li>If you can't do either, then just use the delete/insert representation</li>
                </ul>

                <h3>Note on this methodology with respect to tables related by foreign key (CSV mode is required)</h3>

                <p>If you have tables that depend on each other via foreign key,
                    <u>
                        <i>you must use the CSV format</i>
                    </u>
                    (which is the preference anyway).
                </p>

                <p>The reason here is that if you have inserts/updates/deletes spanning those related tables, the
                    operations
                    need to be done in the correct foreign-key dependency order.
                </p>

                <p>For example:</p>
                <ul>
                    <li>Say that TableA depends on TableB, and TableB depends on TableC. And you want to insert static
                        data for
                        all those tables
                    </li>
                    <li>Then, the inserts must first be done in TableC, then TableB, then TableA</li>
                    <li>However, the deletions must be done in the
                        <i>reverse</i>
                        order (TableA, then TableB, then TableC)
                    </li>
                </ul>
                <p>Lucky for you, Obevo takes care of this!</p>
                <ul>
                    <li>Obevo knows how your tables are related to each other via FK (assuming you've defined
                        those
                        foreign keys in your table DDLs in the first place), and thus can manage the dependency order
                        accordingly on the CSV side
                    </li>
                    <li>Simply edit the CSV files as you need to, and Obevo takes care of the rest</li>
                </ul>
            </subsection>
            <subsection name="Methodology 2) File-per-staticDataGroup (i.e. common static data across a set of tables)">

                <p>Some use cases lend themselves towards representing static data not per table, but for a set of
                    tables
                    involving a particular context
                </p>

                <p>An example is the DIAT tool from the Reg Ops IT team - adding DIAT views spans across multiple tables
                    with
                    those rows being linked to each other; but the rows per DIAT view do not interact with other rows in
                    those
                    tables. Hence, it is preferable to keep these separate.
                </p>

                <p>Hence, your files may make sense to represent like this (taking the same content above, but represent
                    it in
                    the staticDataGroup mode)
                </p>
                <source><![CDATA[### position-view.sql ###
delete from view where view_id = 1
delete from column_def where column_id in (20,21,22)
delete from view_columns where view_id = 1

insert into view (1, "position")

insert into view_columns (1, 20)
insert into view_columns (1, 21)
insert into view_columns (1, 22)

insert into column_def (20, "col1")
insert into column_def (21, "col2")
insert into column_def (22, "col3")]]></source>
                <source><![CDATA[### transaction-view.sql ###
delete from view where view_id = 5
delete from column_def where column_id in (20,21,22)
delete from view_columns where view_id = 5

insert into view (5, "transaction")

insert into view_columns (5, 50)
insert into view_columns (5, 51)
insert into view_columns (5, 52)

insert into column_def (50, "txncol1")
insert into column_def (51, "txncol2")
insert into column_def (52, "txncol3")]]></source>
                <p>Note that:</p>
                <ul>
                    <li>We use delete-insert for this methodology. CSV is not yet supported for this, but will be in the
                        future
                    </li>
                    <li>Each file needs the deletes to come first in the first so that this script can be rerunnable,
                        then
                        followed by the inserts. The deletes/inserts should follow the appropriate FK order (i.e. delete
                        the
                        dependents first, insert the dependencies first)
                    </li>
                </ul>
                <p>Though the file name is not strictly a &quot;db-object&quot; view at this point, it is still a
                    rerunnable
                    script and makes more sense from a maintainability perspective, so go right ahead and do it if it
                    makes
                    sense for your use case!
                </p>
            </subsection>
        </section>
        <section name="Ad-hoc data migrations">
            Note from the author to those who read this section for past versions: yes, this text has changed a lot :) -
            we now support ad-hoc data migrations, as we recognize that some teams are fine to do backwards-incompatible
            changes whereas others do not. Will explain more below.

            <subsection name="Explaining the use case">
                <p>Use this for one-time data migrations on your transactional tables (i.e. not the static data tables).</p>

                <p>Note that these kinds of SQLs can easily be executed within the /table files themselves, as
                    ultimately those just execute SQLs. In fact, the format of the /migration files is the same as the
                    format of the /table files.</p>

                <p>So when would you define the changes in /migration files vs. /table files?</p>

                <p>
                    <u><b>Migrations in /table file?</b></u>: Very simple backfills of newly added columns (e.g. the snippet below)
                </p>
                <source><![CDATA[
alter table TABLE_A add new column MYCOL
GO
update TABLE_A set MYCOL = 0
GO]]></source>

                <p>
                    <u><b>Migrations in /migration file?</b></u>: some use cases:
                    <ul>
                        <li>If the migration involved multiple tables; thus, it wouldn't make sense to house this in a
                        table-specific file.</li>
                        <li>A one-time update that you don't want to see continuously executed as part of your schema
                            definition, say for your test schemas or in-memory db schemas or correcting missing GRANT statements.
                        </li>
                        <li>For backwards-incompatible updates, where some new column/table needs to be populated from
                        the old one, and then the old column/table needs to be dropped.</li>
                        <li>See the example below (note the "dependencies" attribute in the removeOldCol change and
                            migration2 file that<a href="#DB_Object_Deployment_Order">we mentioned above</a>): splitting
                        the migration into a separate section lets us clearly see what the schema should look like in
                        the /table file, while letting the migration be defined elsewhere.</li>
                    </ul>
                </p>
                <source><![CDATA[{/table/TABLE_A.sql file}
//// CHANGE name="init"
CREATE TABLE TABLE_A (COL1 INT, COL2 INT, ...)
GO
//// CHANGE name="addNewCol2"
ALTER TABLE TABLE_A ADD NEWCOL2 (INT)
GO

//// CHANGE name="removeOldCol" dependencies="migration2.step1"
ALTER TABLE TABLE_A DROP COL2
GO

{/migration/migration2.sql file}
//// CHANGE name="step1" dependencies="TABLE_A.addNewCol2"
UPDATE TABLE_A SET NEWCOL2 = COL2 + 1
GO]]></source>
            </subsection>

            <subsection name="Usage Details">
                <p>1) Define the files in the /migration folder</p>

                <p>2) File content is the same as for tables, i.e.
                    <ul>
                        <li>Use //// CHANGE entries as needed.</li>
                        <li>//// METADATA section and attributes like includeEnvs/excludeEnvs still apply.</li>
                    </ul>
                </p>

                <p>Differences from /table representation:</p>
                <p>A) The file name need not correspond to a db-object name. You are free to name this as you please.</p>

                <p>B) You <b><i>are allowed to delete /migration CHANGE entriesafter being deployed</i></b>.
                    This is because we don't want/need migrations lying around in the
                code, as they are one-time activities. Deleting the entries will <i>UNMANAGE</i> them from
                Obevo, akin to the <i>UNMANAGE</i>/delete operation with static data tables. i.e. if the
                migration file is deleted, the entry is removed from the audit table, and Obevo leaves the
                table untouched otherwise.
                </p>
            </subsection>
        </section>
    </body>
</document>