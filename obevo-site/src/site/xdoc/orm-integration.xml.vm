<?xml version="1.0" encoding="UTF-8"?>
#*
 * Copyright 2017 Goldman Sachs.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *#
<document xmlns="http://maven.apache.org/XDOC/2.0"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/XDOC/2.0 http://maven.apache.org/xsd/xdoc-2.0.xsd">
    <properties>
        <title>ORM Integration</title>
    </properties>
    <body>
        <macro name="toc">
            <param name="fromDepth" value="0" />
            <param name="toDepth" value="1" />
        </macro>
        <section name="Use Case Description">
            <p>A standard practice nowadays in db programming is to use ORM tools, like Hibernate or Mithra, to
                interact
                with your database in your systems. These tools provide a way to map from your Java objects to your
                DB
                objects. If you are on an existing system and schema, you would have to rely on the mapping
                abilities of the
                framework to map to your schema.
            </p>
            <p>These ORMs also come with a feature to generate a DB schema from your object model; i.e. to &quot;forward-engineer&quot;
                what the schema should be. If you were starting a system from scratch, then this is great - you can
                define
                your objects in one place, and then generate your schema from there, so that you can keep your DB
                and Java
                objects in sync, as opposed to needing to make changes in two places...
            </p>
            <p>...However, the ORM tools will generate the full version of your table; it will not generate the
                alters to
                get you from whatever is in your Java objects to the actual DB (or at least, it is not easily to
                leverage
                such features in practice, or you need to have a finer control over the table change anyway).
            </p>
            <p>But still, this is an overall positive - you will get the initial version of your table ddl, and the
                baselined version. Obevo has a plugin for Hibernate to generate the table DDLs from a
                Hibernate
                configuration and to output it to the format that Obevo expects (and leaving room for the
                third
                piece to create subsequent alters, which we'll go through in the next section).
            </p>
        </section>
        <section name="Hibernate Integration">
            <subsection name="High Level Steps to Execute">
                <ol style="list-style-type: decimal">
                    <li>You will leverage the obevo-db-hibernate jar and maven plugin to call out to the
                        Hibernate DDL generation code
                    </li>
                    <li>You would have to provide your Hibernate configuration to the maven plugin (expressed via the
                        HibernateSchemaGenFactory class)
                    </li>
                </ol>
            </subsection>
            <subsection name="Example">
                <p>1) Add this dependency to your pom:</p>
                <source><![CDATA[<dependency>
    <groupId>com.goldmansachs.obevo</groupId>
    <artifactId>obevo-db-hibernate</artifactId>
    <version>${project.version}</version>
</dependency>
<dependency>
    <groupId>com.goldmansachs.obevo</groupId>
    <artifactId>obevo-db-sybase-ase</artifactId>  <!-- or whatever your implementation is -->
    <version>${project.version}</version>
</dependency>]]></source>
                <p>2) Create a class that implements the HibernateSchemaGenFactory interface. All that interface does is
                    return
                    a HibernateSchemaGenConfig instance class, the main field being your Hibernate Configuration object
                    (whether
                    you get it from annotations or xml doesn't matter). See the example below, and look at the Javadoc
                    in your
                    IDE for details:
                </p>
                <source><![CDATA[public static class ExampleSchemaGenFactory implements HibernateSchemaGenFactory {
    @Override
    public HibernateSchemaGenConfig getSchemaGenConfig() {
        Configuration hibConfig = new Configuration();
        hibConfig.addAnnotatedClass(HibClassA.class);
        hibConfig.addAnnotatedClass(HibClassB.class);
        hibConfig.addAnnotatedClass(HibClassSchemaC.class);
        hibConfig.addAnnotatedClass(HibClassSchemaD.class);
        hibConfig.buildMappings();
        AuditConfiguration.getFor(hibConfig);

        return new HibernateSchemaGenConfig(new AseDbPlatform())
                    hibConfig,
                    SybaseASE15Dialect.class,
                    new File(&quot;./target/hibgentest&quot;),
                    &quot;dot&quot;)
                    .withShouldOverwritePredicate(HibernateSchemaGenerator.overwriteAllPredicate())
                    .withPostCreateTableSql(&quot; lock datarows&quot;);
    }
}]]></source>
                <p>3) Add the following maven plugin to your pom so that the schema is generated in your project. Pass
                    in the
                    class that you just created as the &lt;schemaGenFactoryClass&gt; argument
                </p>
                <source><![CDATA[<plugin>
    <groupId>com.goldmansachs.obevo</groupId>
    <artifactId>obevo-maven-plugin</artifactId>
    <version>${obevo.version}</version>
    <executions>
        <execution>
            <id>generate-ddls</id>
            <goals>
                <goal>hibernate-schema-generate</goal>
            </goals>
            <phase>generate-test-sources</phase>
            <configuration>
                <schemaGenFactoryClass>com.myapp.ExampleSchemaGenFactory</schemaGenFactoryClass>
            </configuration>
        </execution>
    </executions>
</plugin>]]></source>
                <p>3a) In terms of whether to put your class as src/main/java or src/test/java or when to run this
                    plugin, the
                    recommendation is:
                </p>
                <ul>
                    <li>Put the class in src/main/java</li>
                    <li>Run the plugin during generate-test-sources</li>
                </ul>
                <p>This is because your unit tests may want to have these DDL files available for an in-memory db, so
                    you'd want
                    it created before tests. But to generate this, you may need to create your config, and thus you need
                    to have
                    it after your src/main/java compilation
                </p>
                <p>4) This will create the DB files in the folder that you specified. Most of the files will be in the
                    /table
                    folders. Your //// CHANGE files are in here - this was the first piece of the puzzle above. These
                    files will
                    only be created if they don't already exist; they cannot be overwritten per the contract above. So
                    the first
                    time you create the model, these are up to date, but after some changes, they will not and you need
                    to add
                    //// CHANGE entries.
                </p>
                <p>But note - there is a generated folder under there, and the files end in .baseline.sql and don't have
                    ////
                    CHANGE entries. These are the baseline files. Great - this is the second piece of the puzzle! You
                    now know
                    what your table ideally looks like, and when you create your alter statements, you know what SQL you
                    need to
                    strive form.
                </p>
                <p>But now the last piece of the puzzle - how to generate your alters and/or ensure that your cumulative
                    CHANGEs
                    match the baseline table? Glad you asked -- see the next section:
                </p>
            </subsection>
        </section>
        <section name="Mithra Integration">
            <subsection name="Reverse-engineering files generated from Mithra">
                <p><b>Step 1:</b> generate the DDLs using the Mithra API. (See the Mithra documentation for how to do this).
                    This will result in an output directory structure like this:</p>
                <source><![CDATA[H:\yourInputDir\APP_INFO_DEPLOYMENT_SERVER.ddl
H:\yourInputDir\APP_INFO_DEPLOYMENT_SERVER.fk
H:\yourInputDir\APP_INFO_DEPLOYMENT_SERVER.idx
H:\yourInputDir\APPLICATION_USER_ROLE.ddl
H:\yourInputDir\APPLICATION_USER_ROLE.idx]]></source>

                <p><b>Step 2:</b> Run the Obevo reverse-engineering command to get those files into the Obevo format:</p>

                <p>Via Command Line:</p>
                <source>%OBEVO_HOME%\bin\deploy.bat MITHRAREVENG -dbType DB2 -inputDir h:\reveng-example -outputDir h:\reveng-example-output [-dontGenerateBaseline] [-dbSchema yourSchemaName]</source>
                Argument
                <ul>
                    <li>dbType: (Required) The DBMS type that the DDLs were generated for; use one of the following values - DB2, SYBASE_ASE, SYBASE_IQ, POSTGRESQL, H2, HSQL</li>
                    <li>inputDir: (Required) The directory that contains the Mithra DDLs</li>
                    <li>outputDir: (Required) The directory to write the Obevo DDLs. The format would look like below.
                        <source><![CDATA[H:\yourOutputDir\yourSchema\table\APP_INFO_DEPLOYMENT_SERVER.sql
H:\yourOutputDir\yourSchema\table\APPLICATION_USER_ROLE.sql
H:\yourOutputDir\yourSchema\table\baseline\APP_INFO_DEPLOYMENT_SERVER.baseline.sql
H:\yourOutputDir\yourSchema\table\baseline\APPLICATION_USER_ROLE.baseline.sql]]></source>
                    </li>
                    <li>dontGenerateBaseline: (Optional) Whether to generate the baseline files. See
                        <a href="baseline-validation.html">the Baseline Validation Page</a> for more information</li>
                    <li>dbSchema: (Optional) </li>
                </ul>


                <p>Via Java API:
                    <ul>
                        <li>Add this to Maven
<source><![CDATA[<dependency>
    <groupId>com.goldmansachs.obevo</groupId>
    <artifactId>obevo-reladomo-util</artifactId>
    <version>${project.version}</version>
</dependency>]]></source>
                        </li>
                        <li>Run this code:
                            <source><![CDATA[ReladomoSchemaConverter mithraSchemaConverter = new ReladomoSchemaConverter();
reladomoSchemaConverter.convertReladomoDdlsToDaFormat(platform, new File("./src/test/resources/reveng/input"), outputFolder, "yourSchema", true);]]></source>
                        </li>
                    </ul>
                </p>

            </subsection>
            <subsection name="Generating DDLs directly from Reladomo API">
                In the future, we would like to support generating the Reladomo DDLs directly from an API (as opposed to
                having to generate the DDLs first in the Reladomo format and then reverse-engineering to the Obevo
                format). This is not yet available.
            </subsection>
        </section>
    </body>
</document>